{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f4019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20126f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Local\\Temp\\ipykernel_18404\\3611611429.py:4: DtypeWarning: Columns (15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/reviews83325.csv\")\n",
      "C:\\Users\\Thomas\\AppData\\Local\\Temp\\ipykernel_18404\\3611611429.py:8: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date_review'] = pd.to_datetime(df['date_review'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'avis avant : 340385\n",
      "Nombre d'avis après : 72588\n",
      "Nombre moyen d'avis par lieu : 33.6\n",
      "Maximum d'avis pour un lieu : 100\n",
      "Minimum d'avis pour un lieu : 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Chargement du fichier\n",
    "df = pd.read_csv(\"data/reviews83325.csv\")\n",
    "\n",
    "# 2. Conversion de la date en format datetime pour pouvoir trier\n",
    "# Pandas est assez intelligent pour détecter le format, sinon on peut spécifier format='%Y-%m-%d'\n",
    "df['date_review'] = pd.to_datetime(df['date_review'])\n",
    "\n",
    "# 3. Tri des données : par destination, puis par date (de la plus récente à la plus ancienne)\n",
    "df_sorted = df.sort_values(by=['idplace', 'date_review'], ascending=[True, False])\n",
    "\n",
    "# 4. Groupement par idplace et sélection des 100 premières lignes pour chaque groupe\n",
    "df_cleaned = df_sorted.groupby('idplace').head(100)\n",
    "\n",
    "# 5. (Optionnel) Vérification\n",
    "print(f\"Nombre d'avis avant : {len(df)}\")\n",
    "print(f\"Nombre d'avis après : {len(df_cleaned)}\")\n",
    "print(f\"Nombre moyen d'avis par lieu : {df_cleaned.groupby('idplace').size().mean():.1f}\")\n",
    "print(f\"Maximum d'avis pour un lieu : {df_cleaned.groupby('idplace').size().max()}\")\n",
    "print(f\"Minimum d'avis pour un lieu : {df_cleaned.groupby('idplace').size().min()}\")\n",
    "\n",
    "# 6. Sauvegarde du nouveau fichier nettoyé\n",
    "df_cleaned.to_csv('review_filtered_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122f754",
   "metadata": {},
   "source": [
    "### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0326dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 775.34it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodage des avis en vecteurs...\n",
      "Destination recommandée : Place des Vosges (Score: 4.9436)\n",
      "Destination recommandée : 4ème arrondissement (Score: 3.1766)\n",
      "Destination recommandée : Square de l'Ile de France (Score: 1.5784)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger les données nettoyées\n",
    "df = pd.read_csv('review_filtered_100.csv')\n",
    "df_places = pd.read_csv('data/Tripadvisor.csv')\n",
    "\n",
    "# 2. Générer les vecteurs (Embeddings)\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"Encodage des avis en vecteurs...\")\n",
    "\n",
    "\n",
    "# On encode tous les avis du CSV\n",
    "# corpus_embeddings = model.encode(df['review'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# # Sauvegarder les vecteurs\n",
    "# np.save('avis_embeddings.npy', corpus_embeddings)\n",
    "\n",
    "# # Sauvegarder l'index des avis pour garder la correspondance\n",
    "# df.to_csv('df_final_indexed.csv', index=False)\n",
    "\n",
    "corpus_embeddings = np.load('avis_embeddings.npy')\n",
    "df = pd.read_csv('df_final_indexed.csv')\n",
    "\n",
    "# 3. Fonction de recommandation\n",
    "def recommander_destination(nouvel_avis, top_n=3):\n",
    "    # Vectoriser l'avis d'entrée\n",
    "    query_embedding = model.encode([nouvel_avis])\n",
    "    \n",
    "    # Calculer la similarité entre l'input et toute la base\n",
    "    similarities = cosine_similarity(query_embedding, corpus_embeddings)[0]\n",
    "    \n",
    "    # Récupérer les indices des avis les plus proches\n",
    "    top_indices = np.argsort(similarities)[-20:][::-1] # on prend les 20 meilleurs avis\n",
    "    \n",
    "    # Créer un score par lieu (idplace)\n",
    "    scores_lieux = {}\n",
    "    for idx in top_indices:\n",
    "        id_lieu = df.iloc[idx]['idplace']\n",
    "        score = similarities[idx]\n",
    "        scores_lieux[id_lieu] = scores_lieux.get(id_lieu, 0) + score\n",
    "        \n",
    "    # Trier les lieux par score cumulé\n",
    "    lieux_tries = sorted(scores_lieux.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Afficher les noms des lieux\n",
    "    for id_l, score in lieux_tries[:top_n]:\n",
    "        nom_lieu = df_places[df_places['id'] == id_l]['nom'].values[0]\n",
    "        print(f\"Destination recommandée : {nom_lieu} (Score: {score:.4f})\")\n",
    "\n",
    "# Test\n",
    "recommander_destination(\"Personally I think it is the most beautiful square of Paris. Well maintained and the area around it gives you opportunities to grab a bite to eat as well.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045428c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
